{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is just some example code showcasing how this can be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import openai\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "import difflib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up OpenAI API key (use your own key here)\n",
    "openai.api_key = 'YOUR_OPENAI_API_KEY'\n",
    "\n",
    "# Sample survey data (replace this with your actual survey data)\n",
    "survey_data = [\n",
    "    {\n",
    "        \"response\": \"The service was great, but the wait time was too long.\",\n",
    "        \"question\": \"Why did you give the above rating?\",\n",
    "        \"context\": \"Customer service feedback\",\n",
    "        \"business_context\": \"Survey about customer satisfaction\"\n",
    "    },\n",
    "    {\n",
    "        \"response\": \"The product was okay, but it could have been more affordable.\",\n",
    "        \"question\": \"What was your overall experience?\",\n",
    "        \"context\": \"Product experience feedback\",\n",
    "        \"business_context\": \"Survey about product quality\"\n",
    "    },\n",
    "    # Add more responses here as needed\n",
    "]\n",
    "\n",
    "# Convert the survey data to a pandas DataFrame for easy manipulation\n",
    "df = pd.DataFrame(survey_data)\n",
    "\n",
    "# Define a function to create the LLM prompt for assigning categories\n",
    "def create_llm_prompt(response, question, context, business_context):\n",
    "    return f\"\"\"\n",
    "    You are an AI assistant helping with a survey analysis. Below is a response to a survey question:\n",
    "    \n",
    "    Question: {question}\n",
    "    Response: {response}\n",
    "    Context: {context}\n",
    "    Business Context: {business_context}\n",
    "\n",
    "    Please assign a category that best describes the response. Provide the category as a single word or short phrase.\n",
    "    Some examples of categories are, Good Cusomter Service, Long Wait Time, Low Stock, Bad Product Quality etc.\n",
    "    \"\"\"\n",
    "\n",
    "# Function to get category from LLM\n",
    "def get_category_from_llm(response, question, context, business_context):\n",
    "    prompt = create_llm_prompt(response, question, context, business_context)\n",
    "    \n",
    "    # Call the OpenAI API with the constructed prompt\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",  # or use any LLM of your choice\n",
    "        prompt=prompt,\n",
    "        max_tokens=60,  # Adjust based on your needs\n",
    "        temperature=0.5,  # Control randomness\n",
    "    )\n",
    "    \n",
    "    # Extract and return the category assigned by the LLM\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Apply the categorization to random 1000 response in the survey data\n",
    "df = df.sample(n=1000)\n",
    "df['category'] = df.apply(\n",
    "    lambda row: get_category_from_llm(\n",
    "        row['response'], row['question'], row['context'], row['business_context']\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "print(df[['response', 'category']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this shows one way to combine categoires, you can choose to do whatever is best for your use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample categories that might have been assigned by the LLM (replace with your actual categories)\n",
    "categories = [\n",
    "    \"excellent\", \"great\", \"good\", \"poor\", \"bad\", \"adequate\", \n",
    "    \"good service\", \"poor customer service\", \"great product\", \"excellent experience\"\n",
    "]\n",
    "\n",
    "# Convert categories to a pandas DataFrame for easy manipulation\n",
    "df_categories = pd.DataFrame(categories, columns=['category'])\n",
    "\n",
    "# Step 1: Cleaning categories (lowercase and removing extra spaces)\n",
    "df_categories['cleaned_category'] = df_categories['category'].str.lower().str.strip()\n",
    "\n",
    "# Step 2: Use string similarity to merge similar categories\n",
    "# We'll use difflib's get_close_matches to find similar categories\n",
    "def merge_similar_categories(df):\n",
    "    unique_categories = df['cleaned_category'].unique()\n",
    "    \n",
    "    # Create a dictionary to store category mappings (i.e., merge them)\n",
    "    category_map = {}\n",
    "    \n",
    "    for cat in unique_categories:\n",
    "        # Find similar categories using difflib\n",
    "        close_matches = difflib.get_close_matches(cat, unique_categories, n=5, cutoff=0.7)\n",
    "        \n",
    "        for match in close_matches:\n",
    "            if match != cat:\n",
    "                # If a match is found, map it to the original category\n",
    "                category_map[match] = cat\n",
    "\n",
    "    # Apply the category mappings to the cleaned categories\n",
    "    df['merged_category'] = df['cleaned_category'].apply(lambda x: category_map.get(x, x))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Merge similar categories based on similarity\n",
    "df_merged = merge_similar_categories(df_categories)\n",
    "\n",
    "# Step 3: Apply custom rules to combine categories (e.g., excellent & great => good, poor & bad => bad)\n",
    "def apply_custom_rules(df):\n",
    "    # Example rules: \n",
    "    # - \"excellent\" and \"great\" are considered \"good\"\n",
    "    # - \"poor\" and \"bad\" are considered \"bad\"\n",
    "    rules = {\n",
    "        'good': ['excellent', 'great', 'good service'],\n",
    "        'bad': ['poor', 'bad', 'poor customer service'],\n",
    "        'adequate': ['adequate'],\n",
    "        'great product': ['great product'],\n",
    "        'excellent experience': ['excellent experience']\n",
    "    }\n",
    "    \n",
    "    # Reverse the dictionary to easily map categories to new categories\n",
    "    rules_reverse = {cat: key for key, values in rules.items() for cat in values}\n",
    "    \n",
    "    # Apply the rules\n",
    "    df['final_category'] = df['merged_category'].apply(lambda x: rules_reverse.get(x, x))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply custom rules to the merged categories\n",
    "df_final = apply_custom_rules(df_merged)\n",
    "\n",
    "# Step 4: Get unique categories after merging and applying rules\n",
    "unique_final_categories = df_final['final_category'].unique()\n",
    "\n",
    "# Show the cleaned and merged categories\n",
    "print(\"Original Categories:\")\n",
    "print(df_categories['category'].tolist())\n",
    "\n",
    "print(\"\\nCleaned and Merged Categories:\")\n",
    "print(df_final[['category', 'merged_category', 'final_category']].drop_duplicates())\n",
    "\n",
    "print(\"\\nFinal Unique Categories:\")\n",
    "print(unique_final_categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assuming we now have a unique list of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume `df_final` contains the cleaned, final categories from the previous steps\n",
    "\n",
    "# Sample data for full responses (in a real use case, these would be your actual responses)\n",
    "responses = [\n",
    "    \"The product was fantastic, I had a great experience!\",\n",
    "    \"The service was poor, I would not recommend this to anyone.\",\n",
    "    \"I had an adequate experience, nothing special but it was fine.\",\n",
    "    \"Great customer service, the staff was really friendly and helpful.\",\n",
    "    \"The product was bad, I was really disappointed.\"\n",
    "] * 100  # Multiply to simulate a larger dataset\n",
    "\n",
    "# Cleaned categories list (from Step 2)\n",
    "final_categories = ['good', 'bad', 'adequate', 'great product', 'excellent experience']\n",
    "\n",
    "# Create prompt for LLM using cleaned categories\n",
    "def create_prompt(responses, final_categories):\n",
    "    prompt = \"We have a list of responses and a list of categories. Your task is to assign each response to a category from the list provided.\\n\\n\"\n",
    "    \n",
    "    # Format the list of categories for the LLM prompt\n",
    "    category_list = \"\\n\".join([f\"- {category}\" for category in final_categories])\n",
    "    prompt += f\"Categories:\\n{category_list}\\n\\n\"\n",
    "    \n",
    "    # Format the responses in the prompt\n",
    "    for idx, response in enumerate(responses, start=1):\n",
    "        prompt += f\"Response {idx}: {response}\\nCategory: _______\\n\\n\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Example prompt creation for the first 5 responses\n",
    "prompt = create_prompt(responses[:5], final_categories)\n",
    "print(prompt)\n",
    "\n",
    "# Simulate running the prompt through an LLM (this is just a simulation for illustration)\n",
    "def simulate_llm_response(prompt):\n",
    "    # Simulated LLM output (in practice, call the API here to get actual responses)\n",
    "    # The model would return categories for each response, simulated as random categories from the final_categories list\n",
    "    return [random.choice(final_categories) for _ in range(len(responses))]\n",
    "\n",
    "# Simulate LLM response for the full dataset\n",
    "llm_responses = simulate_llm_response(prompt)\n",
    "\n",
    "# Step 4: Combine categories based on their count\n",
    "def combine_categories_by_count(df, threshold=5):\n",
    "    # Get the counts of each category\n",
    "    category_counts = df['final_category'].value_counts()\n",
    "    \n",
    "    # Combine categories that appear less than the threshold count\n",
    "    combined_categories = category_counts[category_counts < threshold].index.tolist()\n",
    "    \n",
    "    # Map those categories to a broader category (e.g., 'other')\n",
    "    df['final_category'] = df['final_category'].apply(lambda x: 'other' if x in combined_categories else x)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Adding LLM responses to the dataframe\n",
    "df_full_responses = pd.DataFrame(responses, columns=['response'])\n",
    "df_full_responses['assigned_category'] = llm_responses\n",
    "\n",
    "# Combine categories with low counts (for example, categories with less than 5 occurrences)\n",
    "df_combined = combine_categories_by_count(df_full_responses)\n",
    "\n",
    "# Final unique categories after combining\n",
    "final_combined_categories = df_combined['assigned_category'].unique()\n",
    "\n",
    "print(\"\\nFinal Combined Categories (after applying count-based merging):\")\n",
    "print(final_combined_categories)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrapper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
